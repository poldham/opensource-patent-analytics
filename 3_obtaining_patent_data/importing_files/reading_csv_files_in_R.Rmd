---
title: "importing_csv_files_r"
author: "Paul Oldham"
date: "29 April 2015"
output: html_document
---

##Importing CSV files into R

Comma separated value files (or .csv) files are one of the most common and useful ways for sharing data. This includes patent data. 

This walkthrough covers the basics of importing .csv files into R and will use the freely available [ritonavir](https://drive.google.com/open?id=0B4piiKOCkRPDRlBlcGpxR0tMTms&authuser=0) patent dataset as the example. While we use patent data as the example, this will work for other types of csv data. 

We will cover three approaches to importing files here:

1. Importing csv files from local directories using the standard read.table in the Utils package. 
2. Importing csv files using the new [readr](http://blog.rstudio.org/2015/04/09/readr-0-1-0/) package. 
3. Downloading a csv file from a URL including https: connections. 
4. Writing csv files. 

That should cover most needs. If you find that you are stuck with a dataset try calling the description for a particular function (?read.csv) or try [stackoverflow.com](http://stackoverflow.com/questions/tagged/r) results tagged R or from a Google search (often the quickest route).  

##Reading in a file using read.table (Utils package)

Reading in a .csv file is easy and is part of read.table in the R Utils package (installed by default). We can simply read in a .csv by creating an object linked to the function read.csv followed by the path to the local file as follows. 

```{r eval=FALSE}
ritonavir <- read.csv("/Users/colinbarnes/Desktop/open_source_master/2_DATASETS/ritonavir/ritonavir.csv")
```

In some European countries the delimiter in a .csv is a semicolon ";" and not a comma. In the unlikely event you come across these files use read.csv2() as above instead of read.csv.

You now have a dataset called ritonavir in R. That is how easy it is. You can take a look at the data by simply typing ritonavir into the console. What you will see is a mass of data. We can improve on that by using head(ritonavir) but it is still a little difficult to view. We will come back to this in turning the data into a table data frame (tbl_df()). 

First, let's look at the function read.csv and its arguments in a bit more detail to understand what is going on. 

```{r eval=FALSE}
?read.csv ##calls the description for read.table.
```

read.csv(file, header = TRUE, sep = ",", quote = "\"", dec = ".", fill = TRUE, comment.char = "", ...)

##[Note that dec = "." may be causing the problem with the publication date separator as it reads it as a decimal separator]

The arguments for this function can be very useful, for example, 

header = TRUE or FALSE. Determines whether or not to import headings from the first row. 
sep = "," . The separator for the values in each row.

The ... refers to additional arguments that might be applied. Among the most important of these using this function are:

1. stringsAsFactors = FALSE. To prevent character columns being converted to factors. 
2. na.strings = "NA". NA refers to not available. In some cases this needs to be expanded to cover blank cells in the source data. for example c("NA", " ", "") captures cells containing "NA", cells with only a space " " or empty cells "". 
3. strip.white = TRUE. This will strip leading and trailing white space. Note that this will only work if you have specified sep = in the arguments. 
4. skip = n. Specify the number of lines to skip before the data starts. Very useful for data tables with blank rows or text padding at the top of files. 

This means that we would often want a read.csv function with the following additional arguments for our file.  

```{r eval=FALSE}
ritonavir1 <- read.csv("/Users/colinbarnes/Desktop/open_source_master/2_DATASETS/ritonavir/ritonavir.csv", sep = ",", na.strings = "NA", strip.white = TRUE, stringsAsFactors = FALSE)
```

Note here that the use of sep = "," is the condition for stripping leading and trailing white space on import using strip.white = TRUE. 

If you intend to split the inventor and applicant data following import you may want to wait because the process will generate white space. It is always possible to write a .csv file after the cleaning process and reimport it with strip.white set to TRUE along with sep=".". We will write a .csv file below. 

We have not specified skip = n in the above as the column headers are in the first row in the original data. But, there are lots of occassions when skip can be useful. 

Lets look at the type or class of object that has been created from our latest import. 

```{r eval=FALSE}
class(ritonavir1) ##class is "data.frame"
```

If we print the ritonavir R object we will get the first 500 rows of data. 

```{r eval=FALSE}
ritonavir1 ## shows the first 500 rows
```

That is not terribly helpful because we are overwhelmed with information and can't see everything as a snap shot. The solution to this is to install and load the recent dplyr package. We will be using this package a lot in the tutorials so, if you don't have it already, now is a good time.

```{r eval=FALSE}
install.packages("dplyr")
```

load the package

```{r eval=FALSE}
library(dplyr)
```

We can now use the tbl_df() function to creat an easy to read datafarme table using our ritonavir1 dataset that lists columns as characters.

```{r eval=FALSE}
ritonavir2 <- tbl_df(ritonavir1)
```

This creates an easy to read table dataframe.

If we print the frame we will now have readable content. 

```{r eval=FALSE}
ritonavir2
```

That is a lot easier to read than our original (try typing ritonavir into the console to take a look, then try ritonavir 2). 

There are two points to note here. 

1. spaces in column names such as publication number are filled with full stops. 
2. More importantly, by default character vectors are converted to factors (characters backed by a hidden number). While this can be very useful, most of the time it is an inconvenience when working with character vectors. 
[###3. note the decimal issue.] 

We are now good to go. If we wanted to write this data table to a new csv file we would use the following command.

The critical point to remember here is to give the file a new filename or it will overwrite your original data. It is also worth checking your working directory so that you know where it will be saved. 

```{r}
getwd()
```

To write the file with a new file name we will use write.csv()

```{r eval=FALSE}
write.csv(ritonavir2, "ritonavir2.csv", row.names = FALSE)
```

This will write a file called ritonavir2.csv to your working directory. If you do not use row.names = FALSE an extra column will be added in the first column. For some reason a new column will be added every time you write the file. So, it is always best to use row.names = FALSE. 

Column names will now contain fullstops instead of spaces. 

Let's take a look at the options for writing .csv files by calling help. 
```{r}
?write.csv
```

write.csv is a function in write.table.

write.table(x, file = "", append = FALSE, quote = TRUE, sep = " ",
            eol = "\n", na = "NA", dec = ".", row.names = TRUE,
            col.names = TRUE, qmethod = c("escape", "double"),
            fileEncoding = "")

A couple of these settings may be useful.

1. append = TRUE or FALSE. Do we want to append the data to an existing file of that name or not. If false and the same filename is used then it will overwrite the existing file. If TRUE it will append the data to the file of the same name. 
2. na = "NA" the string that you want to use for missing data. This may need further definition depending on your data (e.g. na = c("NA", " ", "")).
3. row.names and col.names may be useful depending on your dataset or needs. Note that the default is TRUE. This is generally correct for columns with patent data but not for rows. 

We have now covered the basics of importing a .csv file into R and then writing a file. Some of these steps are not as easy as they could be. To address that we will look at the recent readr package.

##Reading a .csv from the web

Reading a .csv file from the web is also easy but can involve some complications. We will cover a couple of cases here. If the URL begins with http: then it is as simple as entering the URL inside quotes. However, if it is the secure https: then it is a little bit more of a challenge. 

For example if we try the following it will generally work with http: but not with https:

```{r eval=FALSE}
ritonavir_url <- read.csv("https://drive.google.com/open?id=0B4piiKOCkRPDTGdSQmRMa1BOUEE&authuser=0")
```

The above will throw an error saying https: URLs are not supported.

To deal with this we need to install and load the package RCurl.

```{r eval=FALSE}
install.packages("RCurl")
```

load the library

```{r eval=FALSE}
library(RCurl)
```

Now let's try again. 

```{r eval=FALSE}
ritonavir_url <- download.file("https://drive.google.com/open?id=0B4piiKOCkRPDTGdSQmRMa1BOUEE&authuser=0", "ritonavir_url.csv", method = "curl")
```

In this case we use download.file and the URL in quotes, followed by the destination filename (which will download into the current working directory). For this to work without an error we need finally to specify method = "curl" or an error reading "unsupported URL scheme" will appear. 

###Downloading from GitHub

In downloading from GitHub (where the project Google Drive datasets are also located), we have to go a step further. The URL that you see on the page in Github is basically a marker for the data location... not the actual dataset location. To access the actual dataset navigate to the relevant page [here](https://github.com/poldham/opensource-patent-analytics/blob/master/datasets/ritonavir/ritonavir.csv). However, then select the Raw button and copy that **URL. The URL should begin with https:raw. as below. 

```{r eval=FALSE}
ritonavir_urlg <- download.file("https://raw.githubusercontent.com/poldham/opensource-patent-analytics/master/datasets/ritonavir/ritonavir.csv", "ritonavir_urlg.csv", method = "curl")
```

##Using the new readr package to read .csv  and write csv files.

If you don't have readr use the following to install it. 

```{r eval=FALSE }
install.packages("readr")
```

If you do, or to check it has loaded, use:

```{r eval=FALSE}
library(readr)
```

If you have not done so already, let's install and load dplyr. 

```{r eval=FALSE}
install.packages("dplyr")
```

```{r eval=FALSE}
library(dplyr)
```

Let's try loading our dataset using the function read_csv

```{r eval=FALSE}
ritonavir3 <- read_csv("/Users/colinbarnes/Desktop/open_source_master/2_DATASETS/ritonavir/ritonavir.csv")
```

This will create a data frame and then display problems in red. The problems can be identified using problems(). As with read.csv2, the readr function read_csv2() will read fileswith the ";" as the separator. 

To see the read_csv arguments let's call help

```{r eval=FALSE}
?read_csv
```

read_csv(file, col_names = TRUE, col_types = NULL, na = "NA", skip = 0,
  n_max = -1, progress = interactive())
  
This tells us that the function will assume that there are column names in the first row. col_types = NULL tells us that the function will attempt to calculate the column type from the first thirty rows of data. You can however specify the column types as character, double, integer, logical etc. skip will specify the number of rows to skip as before. n_max will specify the maximum number of records to read. That can be helpful if the dataset is large and you just want to take a look at some of it to get a sense of the data.

The main advantages of read_csv over read.csv are:

-1. read_r does not automatically read in character vectors (columns) as factors. This means there is no need to specify stringsAsFactors = FALSE as part of the function's arguments. This will be a very great relief to many people as it is one less thing to remember! 
-2. The problems() prompt advises you that problems may exist with reading the file. You might be able to fix or ignore them.
-3. For larger files a progress indicator will display on loading (in interactive mode) where the load is over 5 seconds.
-4. Column names are left as is. That means that publication number stays as publication number rather than becoming publication.number and requiring renaming. 
-5. By default, readr turns imported data into a data.frame, a table (tbl) and a table dataframe (tbl_df). That means if you are running dplyr then it will automatically show the first ten rows and the column name. That may not sound exciting but it is a lot better than the alternative. 

However, as read_r is a new package that is being actively developed there are also some issues. The development version is available [here](https://github.com/hadley/readr/blob/master/README.md) 

Let's take a look now at ritonavir3 but using the View() function to call up a dataset window. 

```{r eval=FALSE}
View(ritonavir3)
```

If we scroll across then we can see that the date columns in the dataset have been transformed to NA. In some circumstances this is not a problem (remember that we still have the original dataset, what we see here is a data table). In other case this could be a problem (if we wanted to use this data).

At the time of writing, there does not seem to be a clear way to deal with this issue (but see the development page read.me on precisely this issue). This reflects the difficulty of dealing with dates because they can be ambiguous. We will discuss this elsewhere. 

For the moment, let's call ritonavir3 into the console. 

```{r eval=FALSE}
ritonavir3
```

What we see here is the data with column names left as is. We can also see that most of the columns (vectors) are character vectors and have not been transformed into factors meaning no more stringsAsFactors = FALSE. The date fields have been recognised as dates, but as we have seen have been transformed to NA (not available) because of the lack of clarity on the kind of date. 

We will update this part as clarity on dealing with dates becomes available with readr.

##Writing a .csv file using write_csv

We can easily write a .csv file using the write_csv() function as follows

```{r eval=FALSE}
write_csv(ritonavir3, "ritonavir3.csv")
```

The output from this has the advantage of preserving the column names as is. 

The full list of arguments for write_csv at the moment is 

write_csv(x, path, append = FALSE, col_names = !append)

Where append if TRUE would append the table to the existing file. and col_names would write column names at the top of the file (append = TRUE, !append = FALSE). 

Expect more arguments to be added as readr develops. 

Bear in mind that readr does not possess the functionality of the equivalents as read.csv or write.csv. Because part of the aim is simplification (do a limited number of things well) it is possible that readr may not be as comprehensive as the read.table equivalents in the future. However, readr is likely to become the go to package precisely because of its simplicity for most needs. 

##Round Up

In this walkthrough we have covered the fundamentals of reading and writing .csv files in R. 
